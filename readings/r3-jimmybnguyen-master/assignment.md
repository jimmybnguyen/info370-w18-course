## Overview
The purpose of this assignment is understand the variability in scientific approaches to answering the same question, and to familiarize yourself with some of those approaches. You will be responsible for understanding the details of their procedures, as well as the statistical methods employed. In order to appropriately answer the questions below, you will likely need to **read the papers multiple times**. I suggest that you skim each paper to get a broad understanding, then **re-read the papers** to understand the details. Attempting to answer the questions below without reading the entire paper will both be less accurate and take more time.

## Crowdsourcing Analytics (primary article)

1. Provide an overview of the purpose(s) of this study. Be sure to describe the **specific** contribution it makes to the scientific community. _(10 points)_
> The purpose of this study is to see how different analytical choices affect the results of a dataset for a given research question. While people are aware that results may depend on the analytical strategy, there is little concern for this in actual practice. Some analytics may use a particular analytic strategy because they are comfortable with it, not necessarily because it is the best one. Peer reviews may comment on the strategy being used, but these comments come from their own biases rather than from the dataset itself. Lastly, it is rare for people to challenge an analytic strategy once the research is published. This research study shows much diversity there is in analytic choices with regard to the same data, and how these choices affect the end results.

2. Provide an overview of the procedure of this study -- how did it seek to accomplish its purpose? _(10 points)_
> A project description was posted online, which had an overview of the research question, a description of the dataset, and the project timeline. The project was advertised on Twitter, blogs of academics, and word of mouth. Researchers who were interested in this project was given the dataset from the Open Science Framework project page. In the end, 33 research teams submitted reports in the first round, and 29 teams submitted a final report. 

3. Describe the structure of the dataset, including how data about skin-tone was represented. Then, identify specific limitations the data has for assessing the hypothesis. _(10 points)_
> Demographic data from male soccer players in the 2012-2013 season playing for England, Germany, France, and Spain was obtained from a sports statistic company. This company also had data about the interaction of these players with all referees that they encountered for their **whole** professional career. Skin-tone was coded by two independent raters who did not know the research question. They used a 5 point scale, with *1 = very light skin* and *5 = very dark skin*. This variable was then later rescaled to *0 = very light skin* and *1 = very dark skin* later on. 

> One limitation with this method of representing skin-tone is the subjectivity that is included by having a human rate how dark someone's skin is. One rater's perspective of very dark skin may be very different from another. Also, rescaling a 5 point scale down to 0 or 1 may over represent how dark a player's skin actually is. For example, if someone's skin averages out to a 3.5 from two raters' (*3 = neither dark nor light skin)*, does this become 0 (very light) or 1 (very dark)? 

4. Table 2 shows the frequency of researchers including each covariate in their analysis. Does the distribution surprise you? Why/why not? _(10 points)_
> It makes sense for me that a majority of research teams included the position covariate in their analysis because players in more aggressive positions may be more likely to get red cards. I was surprised to see so many teams using height, weight, and age in their analysis. The research question was about a player's skin-tone, so I am unsure how these covariates relate to that. Lastly, I was surprised at how many covariates some team used versus others. For example, team 1 used seven covariates (position, height, weight, age, league country, club, and referee), and team 9 only used two (position and referee country). Both teams found a statistically significant positive effect, with 9 finding a higher odds ratio (1.48 vs 1.18). 

5. Many of the results (of each individual analysis) are reported in terms of an _odds ratio_. Why is this? Define the odds ratio, and interpret (in plain text) what a specific odds ratio indicates (i.e., _"an odds ratio of 1.34 means that...")_). _(10 points)_
> A majority of the results are reported in terms of an odds ratio because many of research teams are looking at this research study in terms of the number of events / the number of non-events, which can be expressed as *P/(1-P)*. An odds ratio represents the odds that can event will happen given a certain exposure (dark skin tones) versus the odds of the outcome happening in the absence of the same exposure.  An adds ratio of 1.34 means that the odds of a dark skin toned soccer player getting a red card is 1.34 higher than a player that does not have dark skin tones. 

6. How did the authors (of the primary study) answer the question, _do teams with more statistical expertise use different approaches or arrive at different conclusions_? Did answers vary by statistical expertise? Be sure to define any technical terms that you use. _(10 points)_
> The authors of the primary study found that the variability in results could **not** be accounted for by statistical expertise. Analysts with high and low levels of quantitative expertise showed high levels of variability in their estimated effect size, meaning that there was a large range in the final results. During the peer review process, methods that had high praise showed the same variability in the final results as other methods that did not recieve such high praises. 

## Supplement 5

1. Using the data/graphics in this section, describe how analysts' beliefs changed over time. Does this surprise you? Does this give you more or less faith in the scientific process? _(10 points)_
> I was surprised to see so much slight disagreement with the research question at the analytic approach stage, but then a change back to slight agreement in the final report stage. From this, it looks like researchers formed quick opinions after seeing the initial data from their results, but then somehow reverted back to their initial opinion after discussing the results in detail with their teams. This is the part that confuses me the most; I wonder what happened between the analytic approach and final report stages that cause them to go back to their initial opinions. From beginning to end, it looks like a majority of teams did not vary from their initial opinions very much, which worries me because it makes me think that the research teams chose certain covariates that have a greater chance of proving their initial opinions. 

## Team 10 Analysis

1. This team chose to create new variables using the existing one. What new variables did they create, and why did they do this? _(10 points)_
> The first variable they created captured how *physically imposing* a player seems. A more physically imposing player may be more likely to be perceived as committing a violent act, thus more likely to get a red card. This variable was created by converting a player's height and weight into a BMI value. 

>The second variable captured a player's *star status.* A more famous player may be treated more nicely from a referee. This variable was created by taking into account how many goals a player did with the given dataset.

> The last variable they created captured *game situation.* A player on the losing team may act more aggressive or referees may be more attentive towards a losing team. This variable was created by looking at how often a player was on a winning or losing team. 

> These new variables were created in order to test for confounding variables. 

2. In this analysis, the authors tested for _confounding_ prior to the analysis. What is a confounding variable, and what did the authors do with variables they found to be confounding? _(10 points)_
> A confounding variable is an outside influence that changes the effect of the independent and dependent variable. In other words, a confounding variable is an outside force that may ruin the data if not taken into account. The research team tested for variables to be confounding by looking at if they correlated with player skin-tone, and if the variable themselves correlated with the number of red cards received. Any variables that met these criteria were included as covariates in the analysis. 

3. This study attempted to correct for **nested data**. Describe how the data in this study were _nested_, and how the study accounted for this structure. Then, provide an example of another (hypothetical) dataset which would have a nested structure. _(10 points)_
> The red card data was inside every player-referee interaction data point, and the data of referees was inside countries-of-origins data points. This means that you had to go at least three levels deep to get red card data for players. The research team accounted for this data structure by testing a set of adjusted-mean models, which is a way to compensate for data imbalances. This was done by only taking into account the number of red cards received for the number of games in each player-referee dyad. To determine the final model, the research team kept any grouping variable that could show significant variance in red cards above the next simplest level. 

> A hypothetical dataset that would have a nested structure could be car accidents. We could look at each car incident as being inside a person-to-car-maker data point, and car maker data could be inside another variable of country of origin. 

## Team 13 Analysis

1. Describe how (and why) this team manipulated the data prior to analysis. Do you believe the transformations performed were appropriate given the research question? _(10 points)_
> This research team created a new variable for the skin tone of players. They converted average ratings of less than 3 as "light skin" and average ratings of greater than 3 as "dark skin." Any players that were rated at 3 (neutral) were left out. I believe this transformation was appropriate given the research question because it addressed my concerns before on how players that were given two ratings of 3's were classified. If the two independent raters could not tell if a player does not have dark or light skin tones, then I believe 

2. Provide a **thorough** explanation of the modeling approached used by this team. Be sure to provide a detailed explanation of Poisson regression. _(10 points)_
> Team 13 dependent variable for all of their analyses was the number of red cards given within a player-referee dyad. Since this data included count data, they chose to use a Poisson distribution as their model. They confirmed that that the mean and variance of the Poisson distribution was equal, so overdispersion was not an issue. There was also many zeros in the dataset which reflects the rare cases in which no player getting a red card in a game. A Poisson distribution fairs well in modeling rare events. 

> To test *Hypothesis 1: Are soccer referees more likely to give red cards to dark skin toned players than light skin toned players*, they ran a Poisson distributed generalized linear model using the number of red cards as the dependent variable and *log*(games) as the offset variable. Position as included as the covariate, which was a way to control for an observed, continuous variable. Referee and player were included as random effect. They found that a player with dark skin tones had an increase of 41% of receiving a red card versus a player with light skin tones. 

3. Why did the authors need to _offset_ their Poisson model? _(10 points)_
> The authors of team 13 needed to offset their Poisson model because the number of red cards were directly related to the number of interactions a dyad has had. By offsetting, they are able to model **rate** instead of a count. In this case, the rate in which a dark skin toned player received red cards. We're not interested in how many red cards dark skin toned players get, but rather if they are more likely to receive red cards. The offset allows the research team to control how long they are observing these dyads. 